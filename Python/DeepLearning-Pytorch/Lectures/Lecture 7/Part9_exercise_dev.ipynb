{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print your name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise by: Janne Bragge\n"
     ]
    }
   ],
   "source": [
    "## Your code here \n",
    "print(\"Exercise by: Janne Bragge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare fully connected network vs. convolution network performance\n",
    "\n",
    "In this notebook, you'll compare 3 different neural network with same parameter count. First we start with fully connected network (FC), then we try convolutinal network (CNN) and finally we try pretrained densenet (also CNN).\n",
    "\n",
    "We try to make all networks with same parameter count (= 7...8M parameters). Target size you can find from densenet description below. \n",
    "\n",
    "<img src='../data/assets/densenet121.png' width=600>\n",
    "\n",
    "https://pytorch.org/vision/main/models/generated/torchvision.models.densenet121.html\n",
    "\n",
    "**Note.** Running 6 epochs with all these 3 networks takes some time, about 25 min / network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.4.1+cu121\n",
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available() :\n",
    "    device = \"cuda\" \n",
    "else : \n",
    "    device = \"cpu\" \n",
    "\n",
    "print(\"Device =\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise - Data loaders:\n",
    "Define needed transforms for training images and testing images.\n",
    "\n",
    "**Use parameters:**\n",
    "- mini-batch size = BATCH_SIZE\n",
    "- Use normalization: means `[0.485, 0.456, 0.406]` and the stds `[0.229, 0.224, 0.225]`\n",
    "- image size: 224x224 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1:\n",
    "## Your code here \n",
    "\n",
    "# Asetetaan parametrit\n",
    "IMAGE_SIZE =  224 # Kuvan koko 224x224\n",
    "\n",
    "# M√§√§ritell√§√§n tarvittavat transformaatiot\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Skaalaa kuva oikeaan kokoon\n",
    "    transforms.ToTensor(),  # Muuntaa kuvan tensoriksi\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisointi\n",
    "])\n",
    "\n",
    "# Ladataan data\n",
    "train_dataset = datasets.ImageFolder(\"/home/jovyan/shared/Cat_Dog_data/train\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(\"/home/jovyan/shared/Cat_Dog_data/test\", transform=transform)\n",
    "\n",
    "# Luodaan DataLoaderit\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise - Train function:\n",
    "Define train function to train the model.\n",
    "\n",
    "```python\n",
    "def train_model(model, device, epochs) :\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2:\n",
    "## Your code here \n",
    "import time\n",
    "\n",
    "\n",
    "def train_model(model, device, epochs, \n",
    "                train_loader=train_loader, \n",
    "                test_loader=test_loader, \n",
    "                #criterion=nn.BCEWithLogitsLoss(),\n",
    "                criterion=nn.CrossEntropyLoss(), \n",
    "                optimizer_fn=lambda model: optim.Adam(model.parameters(), lr=0.001)):\n",
    "\n",
    "    model.to(device)  # Siirret√§√§n malli oikealle laitteelle (CPU/GPU)\n",
    "    \n",
    "    optimizer = optimizer_fn(model)  # Luodaan optimointialgoritmi\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    start_time = time.time()  # Aloitetaan ajanotto\n",
    "    \n",
    "    for epoch in range(epochs):  \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:  \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            images = images.view(images.size(0), -1)  # üî• Tasoitetaan kuvat (3x224x224 -> 150528)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Lasketaan tarkkuus\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        # Testivaihe\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                images = images.view(images.size(0), -1)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        \n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "        test_accuracies.append(correct_test / total_test)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss= {epoch_loss:.4f}, Train Acc= {epoch_accuracy:.4f}, Test Loss= {test_losses[-1]:.4f}, Test Acc= {test_accuracies[-1]:.4f}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    minutes = int(training_time // 60)\n",
    "    seconds = int(training_time % 60)\n",
    "    print(f\"Finished Training\")\n",
    "    print(f\"Training time is: {minutes}m {seconds}s\")\n",
    "    \n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise - 1. Fully connected network \n",
    "Define and train fully connected network with 3-5 layers and total ~ 8M parameters. \n",
    "\n",
    "**Print following parameters:**\n",
    "- Model parameter count \n",
    "- training time\n",
    "- Save results to following parameters: \n",
    "`fc_train_losses, fc_train_accuracy, fc_test_losses, fc_test_accuracy`\n",
    "\n",
    "***Hint.*** You can use function `count_parameters(model)` to check the model size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully connected network parameters: 9636002\n",
      "Fully connected network trainable parameters: 9636002\n"
     ]
    }
   ],
   "source": [
    "## Task 3:\n",
    "## Your code here \n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size=224*224*3, hidden_sizes=[64, 32], output_size=2): # Kuvan koko 224x224\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, output_size))  # Viimeinen kerros\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # üî• Muutetaan kuva vektoriksi\n",
    "        return self.model(x)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "fcmodel = FullyConnectedNet()\n",
    "train_param_count = count_trainable_parameters(fcmodel)\n",
    "param_count = count_parameters(fcmodel)\n",
    "print(f\"Fully connected network parameters: {param_count}\")\n",
    "print(f\"Fully connected network trainable parameters: {train_param_count}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Train Loss= 1.9805, Train Acc= 0.5150, Test Loss= 0.6894, Test Acc= 0.5514\n",
      "Epoch [2/6], Train Loss= 0.7378, Train Acc= 0.5205, Test Loss= 0.6850, Test Acc= 0.5698\n",
      "Epoch [3/6], Train Loss= 0.7026, Train Acc= 0.5364, Test Loss= 0.6843, Test Acc= 0.5782\n",
      "Epoch [4/6], Train Loss= 0.6985, Train Acc= 0.5509, Test Loss= 0.6751, Test Acc= 0.5878\n",
      "Epoch [5/6], Train Loss= 0.6901, Train Acc= 0.5547, Test Loss= 0.6789, Test Acc= 0.5826\n",
      "Epoch [6/6], Train Loss= 0.6849, Train Acc= 0.5652, Test Loss= 0.6751, Test Acc= 0.5862\n",
      "Finished Training\n",
      "Training time is: 25m 35s\n"
     ]
    }
   ],
   "source": [
    "fc_train_losses, fc_train_accuracies, fc_test_losses, fc_test_accuracies = train_model(fcmodel, device, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - 2. Convolutional network\n",
    "Define and convolutional network with 3-5 convolution layers and total ~ 8M parameters. \n",
    "\n",
    "**Print following parameters:**\n",
    "- Model parameter count\n",
    "- training time\n",
    "- Save results to following parameters: \n",
    "`conv_train_losses, conv_train_accuracy, conv_test_losses, conv_test_accuracy`\n",
    "\n",
    "***Hint.*** You can use function `count_parameters(model)` to check the model size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional network parameters: 6446498\n",
      "Convolutional network trainable parameters: 6446498\n"
     ]
    }
   ],
   "source": [
    "## Task 4:\n",
    "## Your code here \n",
    "\n",
    "class LightNetwork(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_size=2):\n",
    "        super(LightNetwork, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 3, 224, 224)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_layers(x)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "convmodel = LightNetwork()\n",
    "train_param_count = count_trainable_parameters(convmodel)\n",
    "param_count = count_parameters(convmodel)\n",
    "print(f\"Convolutional network parameters: {param_count}\")\n",
    "print(f\"Convolutional network trainable parameters: {train_param_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Train Loss= 0.6912, Train Acc= 0.5984, Test Loss= 0.5945, Test Acc= 0.6793\n",
      "Epoch [2/6], Train Loss= 0.5394, Train Acc= 0.7280, Test Loss= 0.5233, Test Acc= 0.7445\n",
      "Epoch [3/6], Train Loss= 0.4527, Train Acc= 0.7844, Test Loss= 0.4899, Test Acc= 0.7633\n",
      "Epoch [4/6], Train Loss= 0.3769, Train Acc= 0.8325, Test Loss= 0.4601, Test Acc= 0.7881\n",
      "Epoch [5/6], Train Loss= 0.2994, Train Acc= 0.8735, Test Loss= 0.4765, Test Acc= 0.7901\n",
      "Epoch [6/6], Train Loss= 0.2122, Train Acc= 0.9141, Test Loss= 0.5653, Test Acc= 0.7865\n",
      "Finished Training\n",
      "Training time is: 26m 2s\n"
     ]
    }
   ],
   "source": [
    "conv_train_losses, conv_train_accuracies, conv_test_losses, conv_test_accuracies = train_model(convmodel, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - 3. densenet121\n",
    "Define and train fully connected network with 3-5 layers and total ~ 8M parameters. \n",
    "\n",
    "**Print following parameters:**\n",
    "- Model parameter count\n",
    "- training time\n",
    "- Save results to following parameters: \n",
    "`dense_train_losses, dense_train_accuracy, dense_test_losses, dense_test_accuracy`\n",
    "\n",
    "***Hint.*** You can use function `count_parameters(model)` to check the model size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 5:\n",
    "## Your code here \n",
    "\n",
    "\n",
    "from torchvision.models.densenet import DenseNet\n",
    "\n",
    "class LightDenseNet(DenseNet):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__(growth_rate=16, num_init_features=32, block_config=(3, 6, 12, 8))  # Oletus on (6, 12, 24, 16)\n",
    "        self.classifier = torch.nn.Linear(self.classifier.in_features, num_classes)  # Muuta luokkien m√§√§r√§\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Poistetaan litistetyn sy√∂tteen ehto\n",
    "        x = x.view(x.size(0), 3, 224, 224)\n",
    "        return super().forward(x)\n",
    "\n",
    "densemodel = LightDenseNet()\n",
    "#print(sum(p.numel() for p in model.parameters()))  # Katso, kuinka kevyt malli on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Train Loss= 0.5693, Train Acc= 0.6944, Test Loss= 0.5689, Test Acc= 0.7109\n",
      "Epoch [2/6], Train Loss= 0.4227, Train Acc= 0.8065, Test Loss= 0.9341, Test Acc= 0.6417\n",
      "Epoch [3/6], Train Loss= 0.3259, Train Acc= 0.8571, Test Loss= 0.4495, Test Acc= 0.8097\n",
      "Epoch [4/6], Train Loss= 0.2553, Train Acc= 0.8942, Test Loss= 0.8337, Test Acc= 0.7173\n",
      "Epoch [5/6], Train Loss= 0.2036, Train Acc= 0.9153, Test Loss= 0.2996, Test Acc= 0.8721\n"
     ]
    }
   ],
   "source": [
    "dense_train_losses, dense_train_accuracies, dense_test_losses, dense_test_accuracies = train_model(densemodel, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(fc_train_losses)\n",
    "plt.plot(conv_train_losses)\n",
    "plt.plot(dense_train_losses)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Training loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot((fc_train_accuracies))\n",
    "plt.plot(conv_train_accuracies)\n",
    "plt.plot(dense_train_accuracies)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(fc_test_losses)\n",
    "plt.plot(conv_test_losses)\n",
    "plt.plot(dense_test_losses)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Test loss')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot((fc_test_accuracies))\n",
    "plt.plot(conv_test_accuracies)\n",
    "plt.plot(dense_test_accuracies)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Test accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Reflection\n",
    "\n",
    "Answer briefly following questions (in English or Finnish):\n",
    "- Which model is best? Why?\n",
    "- Is there some topics that should have been checked? E.g. training with more epochs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answers here...*\n",
    "\n",
    "1) Analyysin perusteella DenseNet n√§ytt√§√§ olevan paras malli. T√§m√§ johtuu seuraavista tekij√∂ist√§:\n",
    "\n",
    "Alhaisin harjoitus- ja testitappio\n",
    "\n",
    "DenseNetin tappio (loss) on jatkuvasti alhaisin sek√§ harjoitus- ett√§ testivaiheessa verrattuna muihin malleihin. Alhaisempi tappio tarkoittaa, ett√§ mallin ennusteet ovat l√§hemp√§n√§ todellisia arvoja. CN osuu DenseNetin ja FC:n v√§liin. FC n√§ytt√§√§ k√§rsiv√§n korkeasta tappiosta, mik√§ viittaa siihen, ett√§ se ei pysty minimoimaan virheit√§ tehokkaasti.\n",
    "\n",
    "Korkein harjoitus- ja testitarkkuus\n",
    "\n",
    "DenseNet saavuttaa kaikista malleista korkeimman harjoitus- ja testitarkkuuden, mik√§ tarkoittaa, ett√§ se tekee tarkimpia ennusteita. FC suoriutuu huonoimmin, kun taas konvoluutioneuroverkko parantaa suorituskyky√§, mutta ei saavuta DenseNetin tasoa.\n",
    "\n",
    "Parempi yleistyskyky\n",
    "\n",
    "DenseNetin alhainen tappio ja korkea tarkkuus sek√§ harjoitus- ett√§ testidatassa viittaavat siihen, ett√§ se ei k√§rsi merkitt√§v√§st√§ ylisovittamisesta (overfitting).FC n√§ytt√§√§ puolestaan yleistyv√§n heikommin, sill√§ sen tarkkuus pysyy alhaisena. N√§iden mittareiden perusteella DenseNet on tehokkain ja tarkin malli, sill√§ se minimoi virheet ja saavuttaa parhaan ennustustuloksen.\n",
    "\n",
    "2) Teht√§v√§t sis√§lsiv√§t vain viisi harjoituskierrosta (epochia), mik√§ on todenn√§k√∂isesti liian v√§h√§n kaikkien mallien t√§yden potentiaalin saavuttamiseksi. Pidempi harjoittelu voisi parantaa t√§ysin yhdistetyn ja konvoluutioneuroverkon suorituskyky√§. Kuitenkin DenseNet suoriutuu jo nyt parhaiten, joten se olisi todenn√§k√∂isesti silti paras vaihtoehto pidemm√§ll√§ harjoittelulla.\n",
    "\n",
    "Vaikka DenseNet saavuttaa korkeimman tarkkuuden, on varmistettava, ettei se ylisovita harjoitusdataan.\n",
    "Jos harjoitustarkkuus nousee huomattavasti korkeammaksi kuin testitarkkuus, malli saattaa muistaa harjoitusdatan yksityiskohtia oppimatta yleistett√§vi√§ piirteit√§. Yksi tapa tarkistaa t√§m√§ on verrata harjoitus- ja testitappiota: jos testitappio alkaa kasvaa samalla kun harjoitustappio pienenee, ylisovittamista tapahtuu.\n",
    "\n",
    "Oppimisnopeuden, er√§koon (batch size) ja optimointialgoritmin s√§√§t√§minen voisi parantaa kaikkien mallien suorituskyky√§. DenseNetin paremmuus voi johtua my√∂s siit√§, ett√§ sen valmiit painotukset hyperparametrit on valittu paremmin kyseiseen teht√§v√§√§n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
