{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print your name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise by: Janne Bragge\n"
     ]
    }
   ],
   "source": [
    "## Your code here \n",
    "print(\"Exercise by: Janne Bragge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "In this notebook, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../answers')\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 389,
       "width": 389
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network\n",
    "\n",
    "To make things more concise here, I moved the model architecture and training code from the last part to a file called `fc_model`. Importing this, we can easily create a fully-connected network with `fc_model.Network`, and train the network using `fc_model.train`. I'll use this model (once it's trained) to demonstrate how we can save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.708..  Test Loss: 0.984..  Test Accuracy: 0.682\n",
      "Epoch: 1/2..  Training Loss: 0.991..  Test Loss: 0.736..  Test Accuracy: 0.738\n",
      "Epoch: 1/2..  Training Loss: 0.837..  Test Loss: 0.683..  Test Accuracy: 0.740\n",
      "Epoch: 1/2..  Training Loss: 0.762..  Test Loss: 0.663..  Test Accuracy: 0.734\n",
      "Epoch: 1/2..  Training Loss: 0.783..  Test Loss: 0.638..  Test Accuracy: 0.761\n",
      "Epoch: 1/2..  Training Loss: 0.730..  Test Loss: 0.597..  Test Accuracy: 0.777\n",
      "Epoch: 1/2..  Training Loss: 0.681..  Test Loss: 0.602..  Test Accuracy: 0.780\n",
      "Epoch: 1/2..  Training Loss: 0.677..  Test Loss: 0.573..  Test Accuracy: 0.793\n",
      "Epoch: 1/2..  Training Loss: 0.636..  Test Loss: 0.559..  Test Accuracy: 0.795\n",
      "Epoch: 1/2..  Training Loss: 0.678..  Test Loss: 0.552..  Test Accuracy: 0.791\n",
      "Epoch: 1/2..  Training Loss: 0.638..  Test Loss: 0.548..  Test Accuracy: 0.794\n",
      "Epoch: 1/2..  Training Loss: 0.601..  Test Loss: 0.536..  Test Accuracy: 0.802\n",
      "Epoch: 1/2..  Training Loss: 0.602..  Test Loss: 0.544..  Test Accuracy: 0.801\n",
      "Epoch: 1/2..  Training Loss: 0.631..  Test Loss: 0.577..  Test Accuracy: 0.785\n",
      "Epoch: 1/2..  Training Loss: 0.643..  Test Loss: 0.515..  Test Accuracy: 0.812\n",
      "Epoch: 1/2..  Training Loss: 0.674..  Test Loss: 0.512..  Test Accuracy: 0.811\n",
      "Epoch: 1/2..  Training Loss: 0.654..  Test Loss: 0.520..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.574..  Test Loss: 0.498..  Test Accuracy: 0.813\n",
      "Epoch: 1/2..  Training Loss: 0.582..  Test Loss: 0.483..  Test Accuracy: 0.825\n",
      "Epoch: 1/2..  Training Loss: 0.564..  Test Loss: 0.484..  Test Accuracy: 0.821\n",
      "Epoch: 1/2..  Training Loss: 0.583..  Test Loss: 0.493..  Test Accuracy: 0.816\n",
      "Epoch: 1/2..  Training Loss: 0.559..  Test Loss: 0.482..  Test Accuracy: 0.827\n",
      "Epoch: 1/2..  Training Loss: 0.530..  Test Loss: 0.475..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.559..  Test Loss: 0.485..  Test Accuracy: 0.822\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.503..  Test Accuracy: 0.817\n",
      "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.476..  Test Accuracy: 0.823\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading networks\n",
    "\n",
    "As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's `state_dict`. We can see the state dict contains the weight and bias matrices for each of our layers.\n",
    "\n",
    "**Note.** You can read here, why we are using `state_dict` when saving the model:\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest thing to do is simply save the state dict with `torch.save`. For example, we can save it to a file `'network_A.pth'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'network_A.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('network_A.pth', weights_only=True)\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise: \n",
    "This code will throw an error because the tensor sizes are wrong! Correct it.\n",
    "```python\n",
    "# Code that throws an error\n",
    "loaded_model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "loaded_model.load_state_dict(state_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1:\n",
    "## Your code here \n",
    "\n",
    "loaded_model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "loaded_model.load_state_dict(state_dict)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the checkpoint, along with the state dict. To do this, you build a dictionary with all the information you need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'network_B.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the checkpoint has all the necessary information to rebuild the trained model. You can easily make that a function if you want. Similarly, we can write a function to load checkpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath, weights_only=True)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise: \n",
    "Save model using checkpoint method with filename `example_network.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2:\n",
    "## Your code here \n",
    "torch.save(checkpoint, 'example_network.pth')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's remove original `model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise: \n",
    "Import saved `example_network.pth` to variable `reloaded_model` and print network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3:\n",
    "## Your code here \n",
    "\n",
    "reloaded_model = load_checkpoint('example_network.pth')\n",
    "reloaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise: \n",
    "Test `reloaded_model` by \n",
    "1. Calculate test loss and test accuracy with test dataset.\n",
    "2. Print 1 example image with class probabilities.\n",
    "\n",
    "**Note.** Use `model.eval()`to prevent dropout to work during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = reloaded_model\n",
    "\n",
    "# Load the model and move to the correct device\n",
    "model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "\n",
    "# Compute test loss and accuracy\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No gradient computation needed\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.view(images.shape[0], -1).to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logps = reloaded_model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        ps = torch.exp(logps)  # Convert log probabilities to actual probabilities\n",
    "        top_p, top_class = ps.topk(1, dim=1)  # Get top class\n",
    "        correct += (top_class.view(-1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "       \n",
    "\n",
    "# Compute average loss and accuracy\n",
    "test_loss /= len(testloader)\n",
    "test_accuracy = correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 4:\n",
    "## Your code here \n",
    "print(\"Test Loss: {:.3f}.. \".format(test_loss),\n",
    "        \"Test Accuracy: {:.3f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 5:\n",
    "## Your code here \n",
    "\n",
    "# Import helper module (should be in the repo)\n",
    "import sys\n",
    "sys.path.insert(0, '../answers')\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')\n",
    "\n",
    "example_label = labels[0] \n",
    "example_probabilities = ps\n",
    "\n",
    "print('Label:', labels[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your answers by running following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this code!\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../answers/part6/')\n",
    "from part6_check import *\n",
    "\n",
    "print(\"Reloaded model:\")\n",
    "print(reloaded_model)\n",
    "\n",
    "print(\"\\nTest results:\")\n",
    "test_result_check(test_loss, test_accuracy)\n",
    "\n",
    "print(\"\\nExample:\")\n",
    "print(\"Label: \", example_label)\n",
    "print(\"Probabilities: \", example_probabilities)\n",
    "print(\"Check correct label: \", example_probabilities[:, example_label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
