{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print your name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise by: Janne Bragge\n"
     ]
    }
   ],
   "source": [
    "## Your code here \n",
    "print(\"Exercise by: Janne Bragge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare fully connected network vs. convolution network performance\n",
    "\n",
    "In this notebook, you'll compare 3 different neural network with same parameter count. First we start with fully connected network (FC), then we try convolutinal network (CNN) and finally we try pretrained densenet (also CNN).\n",
    "\n",
    "We try to make all networks with same parameter count (= 7...8M parameters). Target size you can find from densenet description below. \n",
    "\n",
    "<img src='../data/assets/densenet121.png' width=600>\n",
    "\n",
    "https://pytorch.org/vision/main/models/generated/torchvision.models.densenet121.html\n",
    "\n",
    "**Note.** Running 6 epochs with all these 3 networks takes some time, about 25 min / network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.4.1+cu121\n",
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available() :\n",
    "    device = \"cuda\" \n",
    "else : \n",
    "    device = \"cpu\" \n",
    "\n",
    "print(\"Device =\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise - Data loaders:\n",
    "Define needed transforms for training images and testing images.\n",
    "\n",
    "**Use parameters:**\n",
    "- mini-batch size = BATCH_SIZE\n",
    "- Use normalization: means `[0.485, 0.456, 0.406]` and the stds `[0.229, 0.224, 0.225]`\n",
    "- image size: 224x224 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1:\n",
    "## Your code here \n",
    "\n",
    "# Asetetaan parametrit\n",
    "IMAGE_SIZE =  224 # Kuvan koko 224x224\n",
    "\n",
    "# MÃ¤Ã¤ritellÃ¤Ã¤n tarvittavat transformaatiot\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Skaalaa kuva oikeaan kokoon\n",
    "    transforms.ToTensor(),  # Muuntaa kuvan tensoriksi\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisointi\n",
    "])\n",
    "\n",
    "# Ladataan data\n",
    "train_dataset = datasets.ImageFolder(\"/home/jovyan/shared/Cat_Dog_data/train\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(\"/home/jovyan/shared/Cat_Dog_data/test\", transform=transform)\n",
    "\n",
    "# Luodaan DataLoaderit\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise - Train function:\n",
    "Define train function to train the model.\n",
    "\n",
    "```python\n",
    "def train_model(model, device, epochs) :\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2:\n",
    "## Your code here \n",
    "import time\n",
    "\n",
    "\n",
    "def train_model(model, device, epochs, \n",
    "                train_loader=train_loader, \n",
    "                test_loader=test_loader, \n",
    "                #criterion=nn.BCEWithLogitsLoss(),\n",
    "                criterion=nn.CrossEntropyLoss(), \n",
    "                optimizer_fn=lambda model: optim.Adam(model.parameters(), lr=0.001)):\n",
    "\n",
    "    model.to(device)  # SiirretÃ¤Ã¤n malli oikealle laitteelle (CPU/GPU)\n",
    "    \n",
    "    optimizer = optimizer_fn(model)  # Luodaan optimointialgoritmi\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    start_time = time.time()  # Aloitetaan ajanotto\n",
    "    \n",
    "    for epoch in range(epochs):  \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:  \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            images = images.view(images.size(0), -1)  # ðŸ”¥ Tasoitetaan kuvat (3x224x224 -> 150528)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Lasketaan tarkkuus\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        # Testivaihe\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                images = images.view(images.size(0), -1)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        \n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "        test_accuracies.append(correct_test / total_test)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss= {epoch_loss:.4f}, Train Acc= {epoch_accuracy:.4f}, Test Loss= {test_losses[-1]:.4f}, Test Acc= {test_accuracies[-1]:.4f}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    minutes = int(training_time // 60)\n",
    "    seconds = int(training_time % 60)\n",
    "    print(f\"Finished Training\")\n",
    "    print(f\"Training time is: {minutes}m {seconds}s\")\n",
    "    \n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise - 1. Fully connected network \n",
    "Define and train fully connected network with 3-5 layers and total ~ 8M parameters. \n",
    "\n",
    "**Print following parameters:**\n",
    "- Model parameter count \n",
    "- training time\n",
    "- Save results to following parameters: \n",
    "`fc_train_losses, fc_train_accuracy, fc_test_losses, fc_test_accuracy`\n",
    "\n",
    "***Hint.*** You can use function `count_parameters(model)` to check the model size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully connected network parameters: 9636002\n",
      "Fully connected network trainable parameters: 9636002\n"
     ]
    }
   ],
   "source": [
    "## Task 3:\n",
    "## Your code here \n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size=224*224*3, hidden_sizes=[64, 32], output_size=2): # Kuvan koko 224x224\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, output_size))  # Viimeinen kerros\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # ðŸ”¥ Muutetaan kuva vektoriksi\n",
    "        return self.model(x)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "fcmodel = FullyConnectedNet()\n",
    "train_param_count = count_trainable_parameters(fcmodel)\n",
    "param_count = count_parameters(fcmodel)\n",
    "print(f\"Fully connected network parameters: {param_count}\")\n",
    "print(f\"Fully connected network trainable parameters: {train_param_count}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Train Loss= 1.9805, Train Acc= 0.5150, Test Loss= 0.6894, Test Acc= 0.5514\n",
      "Epoch [2/6], Train Loss= 0.7378, Train Acc= 0.5205, Test Loss= 0.6850, Test Acc= 0.5698\n",
      "Epoch [3/6], Train Loss= 0.7026, Train Acc= 0.5364, Test Loss= 0.6843, Test Acc= 0.5782\n",
      "Epoch [4/6], Train Loss= 0.6985, Train Acc= 0.5509, Test Loss= 0.6751, Test Acc= 0.5878\n",
      "Epoch [5/6], Train Loss= 0.6901, Train Acc= 0.5547, Test Loss= 0.6789, Test Acc= 0.5826\n",
      "Epoch [6/6], Train Loss= 0.6849, Train Acc= 0.5652, Test Loss= 0.6751, Test Acc= 0.5862\n",
      "Finished Training\n",
      "Training time is: 25m 35s\n"
     ]
    }
   ],
   "source": [
    "fc_train_losses, fc_train_accuracies, fc_test_losses, fc_test_accuracies = train_model(fcmodel, device, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - 2. Convolutional network\n",
    "Define and convolutional network with 3-5 convolution layers and total ~ 8M parameters. \n",
    "\n",
    "**Print following parameters:**\n",
    "- Model parameter count\n",
    "- training time\n",
    "- Save results to following parameters: \n",
    "`conv_train_losses, conv_train_accuracy, conv_test_losses, conv_test_accuracy`\n",
    "\n",
    "***Hint.*** You can use function `count_parameters(model)` to check the model size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional network parameters: 6446498\n",
      "Convolutional network trainable parameters: 6446498\n"
     ]
    }
   ],
   "source": [
    "## Task 4:\n",
    "## Your code here \n",
    "\n",
    "class LightNetwork(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_size=2):\n",
    "        super(LightNetwork, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 3, 224, 224)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_layers(x)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "convmodel = LightNetwork()\n",
    "train_param_count = count_trainable_parameters(convmodel)\n",
    "param_count = count_parameters(convmodel)\n",
    "print(f\"Convolutional network parameters: {param_count}\")\n",
    "print(f\"Convolutional network trainable parameters: {train_param_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Train Loss= 0.6912, Train Acc= 0.5984, Test Loss= 0.5945, Test Acc= 0.6793\n",
      "Epoch [2/6], Train Loss= 0.5394, Train Acc= 0.7280, Test Loss= 0.5233, Test Acc= 0.7445\n",
      "Epoch [3/6], Train Loss= 0.4527, Train Acc= 0.7844, Test Loss= 0.4899, Test Acc= 0.7633\n",
      "Epoch [4/6], Train Loss= 0.3769, Train Acc= 0.8325, Test Loss= 0.4601, Test Acc= 0.7881\n",
      "Epoch [5/6], Train Loss= 0.2994, Train Acc= 0.8735, Test Loss= 0.4765, Test Acc= 0.7901\n",
      "Epoch [6/6], Train Loss= 0.2122, Train Acc= 0.9141, Test Loss= 0.5653, Test Acc= 0.7865\n",
      "Finished Training\n",
      "Training time is: 26m 2s\n"
     ]
    }
   ],
   "source": [
    "conv_train_losses, conv_train_accuracies, conv_test_losses, conv_test_accuracies = train_model(convmodel, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - 3. densenet121\n",
    "Define and train fully connected network with 3-5 layers and total ~ 8M parameters. \n",
    "\n",
    "**Print following parameters:**\n",
    "- Model parameter count\n",
    "- training time\n",
    "- Save results to following parameters: \n",
    "`dense_train_losses, dense_train_accuracy, dense_test_losses, dense_test_accuracy`\n",
    "\n",
    "***Hint.*** You can use function `count_parameters(model)` to check the model size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 5:\n",
    "## Your code here \n",
    "\n",
    "\n",
    "from torchvision.models.densenet import DenseNet\n",
    "\n",
    "class LightDenseNet(DenseNet):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__(growth_rate=16, num_init_features=32, block_config=(3, 6, 12, 8))  # Oletus on (6, 12, 24, 16)\n",
    "        self.classifier = torch.nn.Linear(self.classifier.in_features, num_classes)  # Muuta luokkien mÃ¤Ã¤rÃ¤\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Poistetaan litistetyn syÃ¶tteen ehto\n",
    "        x = x.view(x.size(0), 3, 224, 224)\n",
    "        return super().forward(x)\n",
    "\n",
    "densemodel = LightDenseNet()\n",
    "#print(sum(p.numel() for p in model.parameters()))  # Katso, kuinka kevyt malli on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Train Loss= 0.5693, Train Acc= 0.6944, Test Loss= 0.5689, Test Acc= 0.7109\n",
      "Epoch [2/6], Train Loss= 0.4227, Train Acc= 0.8065, Test Loss= 0.9341, Test Acc= 0.6417\n",
      "Epoch [3/6], Train Loss= 0.3259, Train Acc= 0.8571, Test Loss= 0.4495, Test Acc= 0.8097\n",
      "Epoch [4/6], Train Loss= 0.2553, Train Acc= 0.8942, Test Loss= 0.8337, Test Acc= 0.7173\n",
      "Epoch [5/6], Train Loss= 0.2036, Train Acc= 0.9153, Test Loss= 0.2996, Test Acc= 0.8721\n"
     ]
    }
   ],
   "source": [
    "dense_train_losses, dense_train_accuracies, dense_test_losses, dense_test_accuracies = train_model(densemodel, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(fc_train_losses)\n",
    "plt.plot(conv_train_losses)\n",
    "plt.plot(dense_train_losses)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Training loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot((fc_train_accuracies))\n",
    "plt.plot(conv_train_accuracies)\n",
    "plt.plot(dense_train_accuracies)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(fc_test_losses)\n",
    "plt.plot(conv_test_losses)\n",
    "plt.plot(dense_test_losses)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Test loss')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot((fc_test_accuracies))\n",
    "plt.plot(conv_test_accuracies)\n",
    "plt.plot(dense_test_accuracies)\n",
    "plt.legend(['Fully connected', 'Convolution network', 'DenseNet'])\n",
    "plt.title('Test accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Reflection\n",
    "\n",
    "Answer briefly following questions (in English or Finnish):\n",
    "- Which model is best? Why?\n",
    "- Is there some topics that should have been checked? E.g. training with more epochs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answers here...*\n",
    "\n",
    "1) Analyysin perusteella DenseNet nÃ¤yttÃ¤Ã¤ olevan paras malli. TÃ¤mÃ¤ johtuu seuraavista tekijÃ¶istÃ¤:\n",
    "\n",
    "Alhaisin harjoitus- ja testitappio\n",
    "\n",
    "DenseNetin tappio (loss) on jatkuvasti alhaisin sekÃ¤ harjoitus- ettÃ¤ testivaiheessa verrattuna muihin malleihin. Alhaisempi tappio tarkoittaa, ettÃ¤ mallin ennusteet ovat lÃ¤hempÃ¤nÃ¤ todellisia arvoja. CN osuu DenseNetin ja FC:n vÃ¤liin. FC nÃ¤yttÃ¤Ã¤ kÃ¤rsivÃ¤n korkeasta tappiosta, mikÃ¤ viittaa siihen, ettÃ¤ se ei pysty minimoimaan virheitÃ¤ tehokkaasti.\n",
    "\n",
    "Korkein harjoitus- ja testitarkkuus\n",
    "\n",
    "DenseNet saavuttaa kaikista malleista korkeimman harjoitus- ja testitarkkuuden, mikÃ¤ tarkoittaa, ettÃ¤ se tekee tarkimpia ennusteita. FC suoriutuu huonoimmin, kun taas konvoluutioneuroverkko parantaa suorituskykyÃ¤, mutta ei saavuta DenseNetin tasoa.\n",
    "\n",
    "Parempi yleistyskyky\n",
    "\n",
    "DenseNetin alhainen tappio ja korkea tarkkuus sekÃ¤ harjoitus- ettÃ¤ testidatassa viittaavat siihen, ettÃ¤ se ei kÃ¤rsi merkittÃ¤vÃ¤stÃ¤ ylisovittamisesta (overfitting).FC nÃ¤yttÃ¤Ã¤ puolestaan yleistyvÃ¤n heikommin, sillÃ¤ sen tarkkuus pysyy alhaisena. NÃ¤iden mittareiden perusteella DenseNet on tehokkain ja tarkin malli, sillÃ¤ se minimoi virheet ja saavuttaa parhaan ennustustuloksen.\n",
    "\n",
    "2) TehtÃ¤vÃ¤t sisÃ¤lsivÃ¤t vain viisi harjoituskierrosta (epochia), mikÃ¤ on todennÃ¤kÃ¶isesti liian vÃ¤hÃ¤n kaikkien mallien tÃ¤yden potentiaalin saavuttamiseksi. Pidempi harjoittelu voisi parantaa tÃ¤ysin yhdistetyn ja konvoluutioneuroverkon suorituskykyÃ¤. Kuitenkin DenseNet suoriutuu jo nyt parhaiten, joten se olisi todennÃ¤kÃ¶isesti silti paras vaihtoehto pidemmÃ¤llÃ¤ harjoittelulla.\n",
    "\n",
    "Vaikka DenseNet saavuttaa korkeimman tarkkuuden, on varmistettava, ettei se ylisovita harjoitusdataan.\n",
    "Jos harjoitustarkkuus nousee huomattavasti korkeammaksi kuin testitarkkuus, malli saattaa muistaa harjoitusdatan yksityiskohtia oppimatta yleistettÃ¤viÃ¤ piirteitÃ¤. Yksi tapa tarkistaa tÃ¤mÃ¤ on verrata harjoitus- ja testitappiota: jos testitappio alkaa kasvaa samalla kun harjoitustappio pienenee, ylisovittamista tapahtuu.\n",
    "\n",
    "Oppimisnopeuden, erÃ¤koon (batch size) ja optimointialgoritmin sÃ¤Ã¤tÃ¤minen voisi parantaa kaikkien mallien suorituskykyÃ¤. DenseNetin paremmuus voi johtua myÃ¶s siitÃ¤, ettÃ¤ sen valmiit painotukset hyperparametrit on valittu paremmin kyseiseen tehtÃ¤vÃ¤Ã¤n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
